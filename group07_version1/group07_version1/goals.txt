Group 7 will implement the algorithm which is proposed in the paper called “GANSeg: Learning to Segment by Unsupervised Hierarchical Image Generation”. Paper proposes a GAN-based approach that generates images conditioned on latent masks, thereby alleviating full or weak annotations required by previous approaches. It also shows that such mask-conditioned image generation can be learned faithfully when conditioning the masks in a hierarchical manner on 2D latent points that define the position of parts explicitly. In the paper, algorithm is used in 5 different datasets and results are showed in terms of IoU and landmark regression (without bias) error in terms of mean L2 distance normalized by inter-ocular distance. 

+--------------------------------------+----------+---------------+-----------+-----------+
| Method                               | Type     | Aligned(K=10) | Wild(K=4) | Wild(K=8) |
+--------------------------------------+----------+---------------+-----------+-----------+
| Thewlis et al. [52]                  | Landmark | 7.95%         | -         | 31.30%    |
+--------------------------------------+----------+---------------+-----------+-----------+
| Zhang et al. [65]                    | Landmark | 3.46%         | -         | 40.82%    |
+--------------------------------------+----------+---------------+-----------+-----------+
| LatentKeypointGAN [14]               | Landmark | 5.85%         | 25.81%    | 21.90%    |
+--------------------------------------+----------+---------------+-----------+-----------+
| Lorenz et al. [34]                   | Landmark | 3.24%         | 15.49%    | 11.41%    |
+--------------------------------------+----------+---------------+-----------+-----------+
| IMM [20]                             | Landmark | 3.19%         | 19.42%    | 8.74%     |
+--------------------------------------+----------+---------------+-----------+-----------+
| DEF [6] by [17]                      | Part     | -             | -         | 31.30%    |
+--------------------------------------+----------+---------------+-----------+-----------+
| SCOPS [17] (w/o saliency)            | Part     | -             | 46.62%    | 22.11%    |
+--------------------------------------+----------+---------------+-----------+-----------+
| SCOPS [17] (w/ saliency              | Part     | -             | 21.76%    | 15.01%    |
+--------------------------------------+----------+---------------+-----------+-----------+
| Liu et al. [32]                      | Part     | -             | 15.39%    | 12..26%   |
+--------------------------------------+----------+---------------+-----------+-----------+
| Huang et al. [16] (w/ detailed label | Part     | -             | -         | 8.40%     |
+--------------------------------------+----------+---------------+-----------+-----------+
| GANSeg                               | Part     | 3.98%         | 12.26%    | 6.18%     |
+--------------------------------------+----------+---------------+-----------+-----------+
Table 1. Landmark detection on CelebA.


Example segmented images can be observed in following URL:
https://github.com/xingzhehe/GANSeg/blob/main/assets/teaser.png

When implementation details are examined, it is observed that 128*128 pixel sizes are used for CelebA dataset. For our experiments, we try to use 64*64 resolution because of the hardware limitation. For quantitive result, we decided to use landmark regression metric which is used in paper specifically. It is good idea to use these metric to compare our result with results that are shown in paper. 
